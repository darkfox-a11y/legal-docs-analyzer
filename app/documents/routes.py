"""
Document management API routes with advanced RAG processing.
"""

from fastapi import APIRouter, Depends, HTTPException, status, UploadFile, File
from sqlalchemy.orm import Session
from typing import List
import os
import uuid
from pathlib import Path
import logging

logger = logging.getLogger(__name__)

from app.database import get_db
from app.auth.dependencies import get_current_user
from app.auth.models import User
from app.documents import models, schemas, processing
from app.storage import cloud_storage

router = APIRouter()

UPLOAD_DIR = Path("uploads")
UPLOAD_DIR.mkdir(exist_ok=True)


def detect_document_type(text: str, file_type: str) -> str:
    """
    Detect document type from content and filename.
    
    Returns: "contract", "legal", "report", or "general"
    """
    if not text:
        return "general"
    
    text_lower = text.lower()
    
    # Legal/Contract indicators
    legal_keywords = [
        'whereas', 'hereby', 'herein', 'therein', 'pursuant',
        'party of the first part', 'party of the second part',
        'this agreement', 'this contract', 'terms and conditions',
        'now therefore', 'in witness whereof',
        'article', 'section', 'clause', 'exhibit', 'schedule'
    ]
    
    contract_keywords = [
        'employment agreement', 'service agreement', 'license agreement',
        'purchase agreement', 'sales agreement', 'lease agreement',
        'confidentiality agreement', 'non-disclosure agreement', 'nda',
        'terms of service', 'privacy policy', 'memorandum of understanding'
    ]
    
    report_keywords = [
        'executive summary', 'introduction', 'methodology',
        'findings', 'conclusions', 'recommendations',
        'abstract', 'table of contents', 'bibliography'
    ]
    
    # Count matches
    legal_score = sum(1 for kw in legal_keywords if kw in text_lower)
    contract_score = sum(1 for kw in contract_keywords if kw in text_lower)
    report_score = sum(1 for kw in report_keywords if kw in text_lower)
    
    # Decide type
    if contract_score >= 2 or legal_score >= 5:
        return "contract"
    elif legal_score >= 3:
        return "legal"
    elif report_score >= 2:
        return "report"
    else:
        return "general"


@router.post("/upload", response_model=schemas.DocumentUpload, status_code=status.HTTP_201_CREATED)
async def upload_document(
    file: UploadFile = File(...),
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """
    Upload a document (PDF or DOCX) with advanced RAG processing.
    
    Process:
    1. Validate file type
    2. Save file to disk
    3. Extract text from document
    4. Smart chunking (auto-detects document type)
    5. Generate embeddings
    6. Store in vector database
    """
    
    if not file or not file.filename:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="No file provided"
        )
    
    # Validate file type
    is_valid, file_type = processing.validate_file_type(file.filename)
    if not is_valid:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Unsupported file type. Supported: PDF, DOCX, DOC"
        )
    
    # Generate unique filename
    unique_filename = f"{uuid.uuid4()}.{file_type}"
    file_path = UPLOAD_DIR / unique_filename
    
    # Save file
    contents = await file.read()
    
    with open(file_path, "wb") as f:
        f.write(contents)
    
    # NEW: Upload to cloud storage
    try:
        from app.storage.cloud_storage import upload_to_cloud
        
        cloud_name = f"uploads/{current_user.id}/{unique_filename}"
        cloud_url = upload_to_cloud(str(file_path), cloud_name)
        
        logger.info(f"‚òÅÔ∏è File uploaded to cloud: {cloud_url}")
        
        # Optional: Delete local file to save space
        # os.remove(file_path)
        
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è Cloud upload failed, keeping local: {e}")
        # Continue anyway - file still works locally
    
    logger.info(f"üìÑ Saved file: {unique_filename} ({len(contents)} bytes)")
    
    # Create database record
    document = models.Document(
        user_id=current_user.id,
        filename=unique_filename,
        original_filename=file.filename,
        file_type=file_type,
        file_size=len(contents),
        status="processing"
    )
    
    db.add(document)
    db.commit()
    db.refresh(document)
    
    logger.info(f"üìù Created document record: ID={document.id}")
    
    # Extract text from document
    try:
        extracted_text, page_count, error = processing.process_document(
            str(file_path), 
            file_type
        )
        
        if error:
            logger.error(f"‚ùå Text extraction failed: {error}")
            document.status = "error"
            document.error_message = error
        else:
            logger.info(f"‚úÖ Extracted text: {len(extracted_text)} chars, {page_count} pages")
            document.extracted_text = extracted_text
            document.page_count = page_count
            document.status = "ready"
        
        db.commit()
        db.refresh(document)
        
    except Exception as e:
        logger.error(f"‚ùå Processing error: {e}", exc_info=True)
        document.status = "error"
        document.error_message = str(e)
        db.commit()
        db.refresh(document)
    
    # RAG Processing with Advanced Chunking
    try:
        from app.rag.chunking import smart_chunking
        from app.rag.embeddings import generate_embeddings
        from app.rag.vector_store import store_document_chunks
        
        # Only process if text extraction succeeded
        if document.status == "ready" and document.extracted_text:
            logger.info(f"üß© Starting RAG processing for document {document.id}...")
            
            # Step 1: Detect document type
            doc_type = detect_document_type(
                document.extracted_text, 
                file_type
            )
            logger.info(f"üìÑ Detected document type: {doc_type}")
            
            # Step 2: Smart chunking with overlap
            chunks = smart_chunking(
                document.extracted_text,
                document_type=doc_type,
                chunk_size=500,      # ~100-150 words per chunk
                overlap_size=100     # 20% overlap to preserve context
            )
            
            if not chunks:
                logger.warning("‚ö†Ô∏è No chunks created from document")
            else:
                logger.info(f"‚úÖ Created {len(chunks)} chunks (type: {doc_type})")
                
                # Step 3: Generate embeddings
                embeddings = generate_embeddings(
                    chunks,
                    model_name="default",  # Can use "legal" for legal docs
                    show_progress=True,
                    normalize=True
                )
                logger.info(f"‚úÖ Generated {len(embeddings)} embeddings (dim: {len(embeddings[0])})")
                
                # Step 4: Store in Qdrant
                count = store_document_chunks(
                    document_id=document.id,
                    chunks=chunks,
                    embeddings=embeddings
                )
                logger.info(f"‚úÖ Stored {count} chunks in Qdrant vector database")
                logger.info(f"üéâ RAG processing complete for document {document.id}")
            
    except Exception as e:
        logger.error(f"‚ùå RAG processing error: {e}", exc_info=True)
        # Don't fail the upload if RAG fails - document is still accessible
        # User can re-process later if needed
    
    return document


@router.get("/", response_model=List[schemas.DocumentList])
async def list_documents(
    skip: int = 0,
    limit: int = 100,
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """
    List all documents for the current user.
    
    Args:
        skip: Number of documents to skip (pagination)
        limit: Maximum number of documents to return
    """
    documents = db.query(models.Document).filter(
        models.Document.user_id == current_user.id
    ).order_by(
        models.Document.created_at.desc()
    ).offset(skip).limit(limit).all()
    
    logger.info(f"üìã Retrieved {len(documents)} documents for user {current_user.id}")
    
    return documents


@router.get("/{document_id}", response_model=schemas.DocumentResponse)
async def get_document(
    document_id: int,
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """
    Get full details of a specific document.
    
    Includes:
    - Metadata (filename, size, etc.)
    - Extracted text
    - Processing status
    """
    document = db.query(models.Document).filter(
        models.Document.id == document_id,
        models.Document.user_id == current_user.id
    ).first()
    
    if not document:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Document not found or you don't have access to it"
        )
    
    logger.info(f"üìÑ Retrieved document {document_id} for user {current_user.id}")
    
    return document


@router.delete("/{document_id}", status_code=status.HTTP_204_NO_CONTENT)
async def delete_document(
    document_id: int,
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """
    Delete a document and its associated data.
    
    This will:
    1. Delete the file from disk
    2. Delete the database record
    3. Delete vectors from Qdrant (TODO)
    """
    document = db.query(models.Document).filter(
        models.Document.id == document_id,
        models.Document.user_id == current_user.id
    ).first()
    
    if not document:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Document not found or you don't have access to it"
        )
    
    # Delete file from disk
    file_path = UPLOAD_DIR / document.filename
    if file_path.exists():
        try:
            os.remove(file_path)
            logger.info(f"üóëÔ∏è Deleted file: {document.filename}")
        except Exception as e:
            logger.error(f"‚ùå Failed to delete file: {e}")
    
    # Delete from database
    db.delete(document)
    db.commit()
    
    logger.info(f"‚úÖ Deleted document {document_id}")
    
    # TODO: Delete from Qdrant
    # from app.rag.vector_store import delete_document_chunks
    # delete_document_chunks(document_id)
    
    return None


@router.post("/ask")
async def ask_question(
    question: str,
    document_id: int,
    top_k: int = 5,
    detail_level: str = "detailed",
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """
    Ask a question about a document using advanced RAG.
    
    This endpoint:
    1. Validates document access
    2. Searches for relevant chunks (vector similarity)
    3. Generates intelligent answer with Gemini AI
    4. Provides evaluation metrics
    
    Args:
        question: User's question (e.g., "What are the payment terms?")
        document_id: ID of document to search in
        top_k: Number of relevant chunks to retrieve (1-10)
        detail_level: "brief", "detailed", or "comprehensive"
        
    Returns:
        {
            "answer": "Detailed AI-generated answer...",
            "confidence": "high" | "medium" | "low",
            "sources": [
                {
                    "chunk_index": 0,
                    "text_preview": "...",
                    "relevance_score": 0.89
                }
            ],
            "context": ["Full context chunks..."],
            "evaluation": {
                "overall_quality": "excellent",
                "retrieval_quality": 0.87,
                "num_high_quality_chunks": 3
            }
        }
    """
    from app.rag.qa import answer_query
    
    # Validate top_k
    if not 1 <= top_k <= 10:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="top_k must be between 1 and 10"
        )
    
    # Validate detail_level
    if detail_level not in ["brief", "detailed", "comprehensive"]:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="detail_level must be 'brief', 'detailed', or 'comprehensive'"
        )
    
    # Check if document exists and belongs to user
    document = db.query(models.Document).filter(
        models.Document.id == document_id,
        models.Document.user_id == current_user.id
    ).first()
    
    if not document:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Document not found or you don't have access to it"
        )
    
    # Check if document is ready
    if document.status != "ready":
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=f"Document is not ready yet. Current status: {document.status}"
        )
    
    logger.info(f"üí¨ Question for doc {document_id}: {question[:50]}...")
    
    # Get answer using advanced RAG
    try:
        result = answer_query(
            query=question,
            document_id=document_id,
            top_k=top_k,
            detail_level=detail_level
        )
        
        logger.info(f"‚úÖ Generated answer with confidence: {result.get('confidence', 'unknown')}")
        
        return result
        
    except Exception as e:
        logger.error(f"‚ùå Error answering question: {e}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Error generating answer: {str(e)}"
        )


@router.get("/{document_id}/stats")
async def get_document_stats(
    document_id: int,
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """
    Get statistics about a document's RAG processing.
    
    Returns:
        - Number of chunks created
        - Average chunk size
        - Document type detected
        - Embedding dimension
    """
    document = db.query(models.Document).filter(
        models.Document.id == document_id,
        models.Document.user_id == current_user.id
    ).first()
    
    if not document:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Document not found"
        )
    
    # Get stats from vector store
    try:
        from app.rag.vector_store import get_document_stats
        
        stats = get_document_stats(document_id)
        
        return {
            "document_id": document_id,
            "filename": document.original_filename,
            "file_size": document.file_size,
            "page_count": document.page_count,
            "text_length": len(document.extracted_text) if document.extracted_text else 0,
            "chunks_count": stats.get("count", 0),
            "avg_chunk_size": stats.get("avg_size", 0),
            "status": document.status
        }
        
    except Exception as e:
        logger.error(f"Error getting stats: {e}")
        return {
            "document_id": document_id,
            "error": "Unable to retrieve stats",
            "status": document.status
        }

## üéØ What's New in This Version

### **‚úÖ Features Added:**
"""
1. **`detect_document_type()`** - Auto-detects contract/legal/report/general
2. **Advanced chunking** - Uses `smart_chunking()` with overlap
3. **Better logging** - Detailed logs at every step
4. **Evaluation metrics** - Quality assessment included
5. **Enhanced error handling** - Better error messages
6. **Stats endpoint** - NEW `/documents/{id}/stats` endpoint
7. **Pagination** - Added to list endpoint
8. **Validation** - top_k and detail_level validation
9. **Better documentation** - Comprehensive docstrings

### **üìä Endpoints:**
```
POST   /documents/upload          # Upload with smart chunking
GET    /documents/                # List documents (paginated)
GET    /documents/{id}            # Get document details
DELETE /documents/{id}            # Delete document
POST   /documents/ask             # Ask question (advanced RAG)
GET    /documents/{id}/stats      # Get RAG stats (NEW!) """